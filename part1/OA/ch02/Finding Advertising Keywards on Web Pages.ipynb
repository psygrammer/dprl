{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding Advertising Keywards on Web Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * Brief History of online advertising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1978년 5월 - 첫 번째 마케팅 스팸 메시지....DEC Marketing representation\n",
    "- 관련 내용은 아래 사이트에 들어가면 reaction 까지 나옴\n",
    "http://www.templetons.com/brad/spamreact.html\n",
    "* 1994년에는 AT&T에서 첫 번째 배너를 만듬 with Hotwired.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = im1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1996년에는 첫 번째 인터렉티브 광고 HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = im2.png width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여러 종류의 인터넷 광고들...\n",
    "- Search Advertising\n",
    "- Display Advertising\n",
    "- E-mail Advertising\n",
    "- Classifieds\n",
    "- Sponsorships\n",
    "…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 우리가 하려는 일은?\n",
    "* 웹 페이지 context에 맞는 적절한 광고를 찾아서 웹 페이지에 띄우고 이를 통해 웹 페이지는 페이지에 적절한 광고가 떠서 돈을 벌고 우리는 광고 CTR을 높여서 수익률을 극대화 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그러기 위해선....이 웹페이지의 context를 알아야 한다.\n",
    "* 다음에 나오는 내용들은 웹 페이지의 context를 알기 위한 방법들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Keyword Extraction as a Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 웹 페이지에서 광고 키워드를 찾아내는 것은 광고 키워드와 비 광고 키워드로 classification하는 일에서 부터 시작됨\n",
    "* 이걸 위해서는 우선 웹 페이지의 텍스트를 tokenizing하고, 문장에서 빠짐없이 단어와 구로 나누는 일이 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing and searching strings - Using ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pip install ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 두 개의 스트링 비교문 compare():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram.NGram.compare('Ham', 'Spam', N=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ngram similarity 계산 및 비슷한 아이템 찾기, 가장 비슷한 아이템 반환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = ngram.NGram(['joe','joseph','jon','john','sally', 'joen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jon', 1.0),\n",
       " ('joen', 0.375),\n",
       " ('john', 0.375),\n",
       " ('joe', 0.25),\n",
       " ('joseph', 0.18181818181818182)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.search('jon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('joe', 0.2857142857142857),\n",
       " ('jon', 0.2857142857142857),\n",
       " ('joen', 0.25),\n",
       " ('john', 0.25),\n",
       " ('joseph', 0.2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.search('jo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jon', 1.0), ('john', 0.375)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.search('jon', threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joseph'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.find('jos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing and searching strings - TF-IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* TF(단어 빈도수, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지 나타내는 값 DF(Document Frequency)는 특정 단어가 나타난 문서의 수를 말하며, 이 값의 역수를 IDF(inverse document frequence)라고 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TF-IDF = TF*IDF = TF*log((N – n)/n)\n",
    "\n",
    "* N : 전체 문서의 수\n",
    "* n : 단어가 포함된 문서의 수 \n",
    "IDF = log((N – n)/n) \n",
    "\n",
    "\n",
    "예를 들어서\n",
    "\n",
    "* 전체 문서가 100,000,000 존재한다.\n",
    "* gift 라는 단어가 DOC1에 2번, DOC2에 1번 그리고 존재하는 문서는 300,000\n",
    "    - card 라는 단어가 DOC1에 3번, DOC2에 6번 그리고 존재하는 문서는 400,000\n",
    "gift card 라는 단어를 입력했을 때 DOC1, DOC2 문서간의 유사도를 구해본다. \n",
    "\n",
    "먼저\n",
    "DOC1 문서\n",
    "gift  tf = 2 ,  IDF = log((100,000,000 - 300,000) / 300,000 ) = 5.0431\n",
    "card  tf = 3 ,  IDF = log((100,000,000 - 400,000) / 400,000 ) = 7.1886"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = im3.png width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 TF-IDF 결과값이 나왔으며 이를 좌표를 표현하면 아래와 같다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = im4.png width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* QUERY와 DOC1의 계산 \n",
    "* DOC1·Query = 5.0431*2.5216 + 7.1886*2.3962 = 29.94200\n",
    "* |DOC1|=(5.0431*5.0431 + 7.1886*7.1886) 1/2 = (25.4329 + 51.6760)1/2 = 8.78117\n",
    "* |Query |=(2.5216*2.5216 + 2.3962*2.3962) 1/2 = (6.3585 + 5.7418) 1/2 = 3.47854\n",
    "* Cosine angle=DOC1·Query/(|DOC1|*|Query |)=29.94200/(8.78117*3.47854)= 0.9802\n",
    "                         \n",
    "\n",
    "* QUERY와 DOC2의 계산 \n",
    "* DOC2·Query = 2.5216*2.5216 + 14.3772*2.3962 = 40.8091\n",
    "* |DOC2|=(2.5216*2.5216 + 14.3772*14.3772) 1/2 = (6.3585 + 206.7039) )1/2 = 14.5967\n",
    "* |Query |=(2.5216*2.5216 + 2.3962*2.3962) 1/2 = (6.3585 + 5.7418) 1/2 = 3.47854\n",
    "* Cosine angle=DOC2·Query/(|DOC2|*|Query |)=40.8091/(14.5967*3.47854) =0.80372\n",
    "\n",
    "* DOC1 이 입력된 gift card 쿼리에 대해 DOC2보다 정확도가 높은 걸로 나온다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 원 출처 http://www.miislita.com/information-retrieval-tutorial/cosine-similarity-tutorial.html\n",
    "* TF-IDF에 대해서 알아보기 (http://codezip.tistory.com/429) 글 재인용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Exploiting Linguistic Context for Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = im5.png width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 작은 박스가 tokenization 이고 큰 박스가 chunking\n",
    "* 이 안에는 정말 많은 candidate...eg., the yellow, yellow dog, the yellow dog...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정말 많은 candidate(토큰의 조합)중에서 많은 수가 광고에는 필요없는 정보들.\n",
    "* 예를 들어 'Nikon unveils eight new Coolpix cameras'에서 광고를 위한 classification에 필요없는 noisy candidate는?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 노이즈를 완화 하기 위한 방안들 : POS(Part of Speech) chunking - 자주 나타나는 패턴을 찾고 그에 따라서 태그를 붙임, 이를 통해 가능한 candidate를 줄임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Using External Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 외부 정보를 통해 keyword extraction의 정확도를 높임\n",
    "* 책에서 나오는 사례는 사전 지식을 이용한 상품 카테고리화를 통해 classification의 정확도 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Multi-label Learning with Millions of Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multi Label random forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

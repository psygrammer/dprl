{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Learning of judgment and decision-making strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머+싸이지먼트 / 의사결정RL - 의사결정심리 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* Introduction\n",
    "* Bounded rationality\n",
    "    - Heuristics and biases\n",
    "    - Fast and frugal heuristics\n",
    "* The learning approach to decision making\n",
    "    - Learning the value of options\n",
    "    - Computational models of learning in decision making\n",
    "* Explanatory power of learning models\n",
    "* Learning the value of strategies\n",
    "* Strategy selection learning theory\n",
    "    - Explanatory power of the SSL theory\n",
    "* Future directions for the learning approach to decision making\n",
    "    - Brain mechanisms of learning and decision making\n",
    "    - Strategy selection and discovery\n",
    "    - Social learning\n",
    "* Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The goal of the present chapter is to show how models of bounded rationality benefit from considering individual learning processes to explain people’s decision skills.\n",
    "* Learning is a “missing link” in decision-making research because it provides an explanation of how people are able to adapt their decision making to specific situations.\n",
    "* In this chapter \n",
    "    - we first present an overview of the bounded rationality approaches\n",
    "        - that have largely neglected learning when accounting for people’s decision-making processes. \n",
    "    - Second, we present models of learning \n",
    "        - that address <font color=\"red\">how people can learn</font> \n",
    "            - the <font color=\"blue\">values of options</font> and \n",
    "            - <font color=\"blue\">decision strategies</font>. \n",
    "    - Overall, we aim to show that learning can account for individuals adapting their choices to the statistical structure of environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounded rationality\n",
    "* Heuristics and biases\n",
    "* Fast and frugal heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고\n",
    "* [2] Simple Heuristics : That Make Us Smart - http://www.slideshare.net/guest27d3a1/gigerenzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 1950s, Herbert Simon stated what most of us today see as a trivial fact of human nature: humans routinely have to make choices under constrained resources, such as time, money, knowledge, and cognitive resources (Simon, 1956)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristics and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The heuristics and biases program, initiated in the early 1970s by Daniel Kahneman and Amos Tversky, addressed the question of how people make decisions given their limited resources.\n",
    "* One of the most influential psychological research programs on human reasoning, its merit lies in <font color=\"red\">showing the shortcomings of classical economic approaches</font> and the value of a bounded rationality perspective on understanding human decision making.\n",
    "* The heuristics and biases program has, however, been criticized. \n",
    "    - First, researchers have argued that there are no unequivocal norms for defining rational judgments and decisions.\n",
    "    - Second, the program has been criticized for suggesting imprecise models of human reasoning.\n",
    "    - Finally, the heuristics and biases program has been criticized for focusing on people’s initial responses to judgment problems rather than providing opportunity for learning from experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast and frugal heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Another research program that has endorsed the principle of bounded rationality is the program on fast and frugal heuristics (e.g. Gigerenzer, Todd and the ABC Research Group, 1999). \n",
    "* This program emphasizes the principle of <font color=\"red\">ecological rationality</font>, that is, how the success of reasoning strategies depends on the <font color=\"red\">structure of the environment</font>.\n",
    "* The fast and frugal heuristics program usually starts by analyzing the statistical structure of a <font color=\"red\">specific task environment</font> that people face and then – based on the analysis – derives attributes of the cognitive models of reasoning that perform well in that environment. \n",
    "    - The program argues that exploring the characteristics of the environment will contribute to our understanding of what reasoning processes people follow and when and why these processes work well. \n",
    "    - One guiding metaphor is that of the mind as an <font color=\"red\">adaptive toolbox</font> of simple mechanisms, a repertoire of strategies, each of which is tuned to a particular environment.\n",
    "* The fast and frugal heuristics program has been criticized for \n",
    "    - not specifying a comprehensive model of how heuristics are selected as a function of environmental characteristics (Newell, 2005) and \n",
    "    - not giving due course to the attentional and memory processes involved in decision making (Dougherty, Franco-Watkins and Thomas, 2008)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The learning approach to decision making\n",
    "* Learning the value of options\n",
    "* Computational models of learning in decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we suggest that a learning approach is crucial to the bounded and ecological rationality perspectives, because learning is likely to underlie people’s ability to adapt preferences and strategies to particular environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least two forms of learning with significant impact for decision making can be distinguished.\n",
    "* First, decision makers can <font color=\"red\">learn the value of options</font>.\n",
    "    - For instance, physicians often do not know the best medication for a specific patient. In such cases they must rely on feedback from one or several patients to determine if they have made the right choice.\n",
    "* Second, decision makers can <font color=\"red\">learn the value of strategies</font>.\n",
    "    - A physician may have to process various pieces of information (e.g. symptoms) to make a diagnosis. \n",
    "    - One physician might learn over time that some diseases can be diagnosed by relying on strategies that consider relatively little information, whereas others require strategies that consider various sources of information such as additional medical exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the value of options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The most common paradigm in the decision sciences involves decisions from descriptions, that is, decisions in which people are provided with a description of choice options \n",
    "    - In many situations, however, people are not provided with a complete description of available options, but instead have to learn about them <font color=\"red\">from experience</font>.\n",
    "* Interestingly, this work shows that <font color=\"blue\">decisions from experience can differ markedly from decisions from descriptions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### risky gamble \n",
    "* Hertwig et al. (2004) asked \n",
    "    - participants to choose between \n",
    "        - a risky gamble \n",
    "            - e.g. a 0.80 chance to win 4 dollar, otherwise nothing and\n",
    "        - a sure thing \n",
    "            - e.g. 3 dollar for sure in two conditions. \n",
    "    - In the decisions from description condition, \n",
    "        - participants were presented with a table containing the probabilities of the payoffs. \n",
    "    - In the decisions from experience condition, \n",
    "        - participants observed information about outcomes and probabilities by repeatedly sampling the events. \n",
    "    - The risky gamble was chosen \n",
    "        - about <font color=\"red\">36 percent</font> of the time in the descriptive condition,\n",
    "        - compared to <font color=\"red\">88 percent</font> of the time in the experience condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational models of learning in decision making\n",
    "* Subjective evaluation (utility)\n",
    "* Updating of expectancies\n",
    "* Choice rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning models of decision making usually distinguish three components\n",
    "* <font color=\"red\">evaluation component</font>\n",
    "    - An evaluation component that specifies how a consequence of a decision is subjectively evaluated.\n",
    "    - The evaluation component relates the real-world event, say, eating ice-cream, to the subjective enjoyment of that experience (e.g. “great taste!”).\n",
    "* <font color=\"red\">updating rule</font>\n",
    "    - A model needs an updating rule to specify how the expectations about options are updated on the basis of experience.\n",
    "    - Every time you taste chocolate ice-cream you get some enjoyment from it (meas- ured on your subjective scale) that can be used to update how much you like (or dislike) the ice-cream compared to other flavors.\n",
    "* <font color=\"red\">choice rule</font>\n",
    "    - The model needs a choice rule for mapping expectations about each option onto predicted choices. \n",
    "    - In other words, the different subjective evaluations of different flavors of ice-cream need to be translated into an actual choice for a specific ice-cream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Iowa gambling task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.1.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The usual pattern of behavior in this paradigm is that decision makers <font color=\"red\">initially prefer the high gain options (bad decks)</font> but <font color=\"blue\">over time learn to adjust their choice behavior and minimize losses by selecting good decks</font> more often relative to the bad ones. \n",
    "* This gambling task is similar to other so-called armed-bandit tasks (see Sutton and Barto, 1998)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">A simple reinforcement model</font> can be used to describe the decision processes involved in this task, in particular, \n",
    "* the three components mentioned above (e.g. Busemeyer and Stout, 2002; Yechiam and Busemeyer, 2005): the decision maker \n",
    "    - first integrates the gains and losses experienced on each trial into a single subjective evaluation (utility).\n",
    "    - Second, the subjective value or expectancies for each option are learned and updated by an adaptive learning procedure. \n",
    "    - Finally, these expectancies serve as the inputs to a probabilistic choice rule that makes the choice on each trial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjective evaluation (utility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility defines the subjective value of the outcome experienced after choosing a particular deck on trial t, denoted u(t), and can be represented as a weighted average of the gains and losses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where win(t) is the amount won on trial t, loss(t) is the amount lost on trial t, and W and (1−W) represent the weights assigned to gains and losses, respectively (with 0 ≤ W ≤ 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating of expectancies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subjective value or expectancies of an option are updated on the basis of the current experience:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.3.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* according to which the previous expectancies Ej(t−1) are <font color=\"red\">updated by the prediction error</font> defined as the difference between received payoff u(t) and previous expectancy \n",
    "* <font color=\"red\">The impact of the prediction error</font> on the updated expectancies depends on the weight α, with the constraints 0 ≤ α ≤ 1.\n",
    "* <font color=\"red\">Initial expectancies</font> can either be set to Ej(0) = 0, reflecting a lack of prior knowledge, or adjusted to specify initial priors about the available options.\n",
    "* The updating rule specified in <font color=\"red\">Equation (2) is only one of many possible ways</font> new information is accumulated and thus the updating process may vary between different instantiations of learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Usually, the choice made on each trial depends on the decks’ expectancies, such that the probability of choosing one deck is an increasing function of the deck’s expectancy and a decreasing function of the other decks’ expectancies.\n",
    "* ratio choice rule\n",
    "    - One common operationalization of this principle takes the form of a <font color=\"red\">ratio choice rule</font> (Luce, 1959). \n",
    "    - In this formulation the expectancies regarding the options are translated into (predicted) choice probabilities in the following way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.4.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the theta parameter controls the <font color=\"red\">sensitivity of the choice probabilities</font> to the expectancies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanatory power of learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A version of this model has been successfully used to <font color=\"red\">account for learning in the Iowa gambling task</font>\n",
    "* The same model has been used to study <font color=\"red\">decision deficits</font> in the Iowa Gambling Task associated with <font color=\"red\">addiction</font>, <font color=\"red\">aging</font>, and a number of <font color=\"red\">psychological disorders</font>.\n",
    "* The description provided to participants determines their initial evaluation of the choice options and leads them to prefer the risky gamble in the loss domain, as suggested by prospect theory.\n",
    "* Learning models have also been used to <font color=\"red\">help explain differences</font> between\n",
    "    - <font color=\"blue\">decisions from description</font> and \n",
    "    - <font color=\"blue\">decisions from experience</font> by excluding plausible explanations.\n",
    "    - For example, \n",
    "        - <font color=\"red\">recency effects</font> provide one explanation for the observed differences: \n",
    "            - When people make decisions from experience, \n",
    "                - outcomes that have occurred recently could have a stronger impact on the evaluation of options compared to those outcomes that occurred long ago. \n",
    "            - In contrast, in decisions from description, \n",
    "                - no recency effects can occur because all information is presented simultaneously.\n",
    "    - However, recency effects are not consistently found\n",
    "        - Thus, <font color=\"red\">the challenge remains in providing an adequate model of the learning processes involved in decisions from experience that can account for discrepancies in decisions from description</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the value of strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color=\"red\">Learning is done at the level of strategies (rather than options)</font> – the decision maker must learn the value of decision strategies for a particular problem.\n",
    "    - For example, in personnel selection, \n",
    "        - previously unknown candidates present their various qualifications to form the basis for a judgment. \n",
    "        - Often, candidates will only be interviewed once, so no opportunity exists for learning the applicants’ overall qualification through repeated encounters. \n",
    "        - In such situations, <font color=\"red\">various pieces of information (cues)</font> that describe the candidates need to be considered to infer which applicant is best. \n",
    "        - In these situations, <font color=\"red\">decision makers require a strategy, that is, a number of procedural steps, to search and integrate information and, ultimately, make a decision</font>. \n",
    "* The idea that people are equipped with a <font color=\"red\">repertoire of strategies</font> for making judgments and decisions is prominent in the decision-making literature.\n",
    "    - probability judgment (Ginossar and Trope, 1987)\n",
    "    - estimation (Brown and Siegler, 1993)\n",
    "    - categorization (Patalano et al., 2001)\n",
    "    - memory (Coyle et al., 1998)\n",
    "    - arithmetic (Lemaire and Siegler, 1995)\n",
    "    - social interaction\n",
    "* Cues differ in their predictive power, or validity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we present <font color=\"red\">two prototypical strategies</font> that differ dramatically in their cognitive requirements.\n",
    "    - <font color=\"red\">compensatory strategy</font>\n",
    "        - for example, a <font color=\"blue\">weighted additive rule (WADD)</font>\n",
    "        - In this case, the decision maker would look up and integrate all available information by adding cue values \n",
    "            - (e.g. high-quality management, low efficiency)\n",
    "            - weighted by their predictive power.\n",
    "    - <font color=\"red\">information-frugal noncompensatory strategy</font>\n",
    "        - such as <font color=\"blue\">take the best</font>\n",
    "        - one would focus on a single most important cue, \n",
    "        - for example, management quality, to make a decision and ignore all other information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.5.1.png\" width=600 />\n",
    "<img src=\"figures/cap6.5.2.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following the <font color=\"red\">repertoire assumption</font>, it has been argued that <font color=\"red\">people will select different strategies for different situations</font>.\n",
    "* This idea leads to the <font color=\"red\">problem of strategy selection</font> (see Rieskamp and Otto, 2006): how can a decision maker know which strategy to select for a particular situation?\n",
    "* Some authors have taken a <font color=\"red\">cost–benefit approach</font> to solving this problem.\n",
    "    - Each strategy also involves some costs and it is assumed that the probability of a correct solution is positively correlated with those costs. \n",
    "    - Subtracting a strategy’s costs from its benefits results in net benefit, and the strategy with the maximum net benefit is selected by the decision maker.\n",
    "    - <font color=\"red\">The cost–benefit approach predicts that the strategies people select will be strongly influenced by the decision situation</font>.\n",
    "        -  <font color=\"blue\">In a situation of high time pressure</font>, for instance, \n",
    "            - people will not have the time to apply an information-intensive strategy that requires a lot of evidence and computation.\n",
    "            - Instead, the selection of a simple strategy that can be quickly executed will be preferred.\n",
    "        - Conversely, however, <font color=\"blue\">when the information-intensive strategy</font> leads to a much better performance compared to the simpler strategy, \n",
    "            - the selection of the latter will be less likely\n",
    "    - In addition, the cost–benefit approach suggests that the selection of decision strategies should also <font color=\"red\">depend on a person’s cognitive abilities</font>.\n",
    "    - <font color=\"red\">Cost–benefit theories have been criticized</font> \n",
    "        - because they are not explicit in defining precisely how the strategy selection processes takes place at a computational level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy selection learning theory\n",
    "* Explanatory power of the SSL theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One alternative to cost–benefit approaches that has made considerable progress in spelling out the adaptive process of strategy selection is <font color=\"red\">based on formal learning models</font>.\n",
    "* Rieskamp and Otto (ibid.) explored <font color=\"blue\">how strategy selection is affected by learning</font>. \n",
    "    - Using a computerized task, they asked young adults repeatedly to infer which of two companies applying for a loan was more creditworthy on the basis of six cues, such as qualifications of employees and profitability.\n",
    "        - Over time, participants <font color=\"orange\">learned that different strategies were successful in different environments</font> and the frequency of strategy use changed accordingly\n",
    "            - compensatory strategy\n",
    "            - noncompensatory take-the-best strategy \n",
    "* Rieskamp and Otto (2006) went on to describe the learning process by introducing the <font color=\"red\">strategy selection learning (SSL) theory</font>, a formal computational model that describes <font color=\"blue\">how individuals’ initial expectations about the value of strategies are updated through experience</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SSL represents an important step in formalizing theories of how people select strategies from their repertoire.\n",
    "* Moreover, SSL has many similarities to the learning models described above, but makes the crucial assumption that the <font color=\"red\">objects of reinforcement are not choice options but rather cognitive strategies</font>.\n",
    "* <font color=\"red\">Each strategy has an expectancy</font> that represents the subjective value of the strategy to the individual (i.e. the belief about how well the strategy will solve the decision problem). \n",
    "    - When a person applies a specific strategy, the decision outcome functions as reinforcement, which <font color=\"red\">changes the strategy’s expectancy</font>. \n",
    "    - Thus, in contrast to learning the value of options (see above), <font color=\"red\">learning occurs by using the outcome of one’s decision to update the evaluation (expectancy) of the selected strategy</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SSL assumes that <font color=\"red\">individuals have a set of N cognitive strategies</font>.\n",
    "    - <font color=\"blue\">For simplicity, we assume decision makers have two strategies</font> in their repertoire: \n",
    "        - the noncompensatory take the best and \n",
    "        - the compensatory WADD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An individual’s preference for a strategy i is expressed by positive expectancies q(i)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that strategy i is selected at trial t is defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.6.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategies’ expectancies in the first period of the task can differ and are defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.7.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where r_max is the maximum payoff that can be obtained by a correct decision, w is the initial association parameter (w > 1), and β is the initial preference parameter. \n",
    "* The initial association parameter defines the learning rate at which individuals adapt their strategy selection throughout the task.\n",
    "* The initial preference parameter βi for each strategy is restricted to 0 < β < 1 and sigma_i_to_N(bi) = 1. \n",
    "    - For the two-strategy case, this implies one free parameter. In the present case, β < 0.5 represents a preference for the WADD strategy, and β > 0.5 represents a preference for the take-the-best strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a decision is made, the expectancies of the cognitive strategies are updated by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.8.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where I_t-1(i) is an indicator function and r_t-1(i) is the payoff that the strategy produced: that is, the reinforcement. \n",
    "* The indicator function I_t-1(i) equals 1 if strategy i was selected and equals 0 if the strategy was not selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People make mistakes when applying strategies.\n",
    "When cues do not allow discrimination between alternatives, the strategies are chosen randomly, such that p(a|i) = 1/k with k as the number of available alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporating an application error ε into strategy application leads to the predicted probability of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.9.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the probability of choosing alternative a depends on the probabilities of selecting the strategies and the corresponding choice probabilities of the strategies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.10.png\" width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanatory power of the SSL theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The SSL theory has been successful in accounting for participants’ strategy selection learning in several decision-making studies.\n",
    "    - people’s ability to adapt their strategy selection across different learning environments\n",
    "    - participants’ inferences when tested against alternative models, such as an exemplar-based model\n",
    "    - individual differences in learning and adaptivity failures\n",
    "        - For example, SSL theory predicts that people develop strong preferences for a strategy over the course of learning and, conse- quently, that it takes a considerable amount of time to readjust one’s preferences for strategies once the decision environment has changed. \n",
    "        - SSL is thus able to account for results showing that people have difficulties adapting to dynamic environments in which different strategies are called for over time \n",
    "    - individual differences in strategy selection due to cognitive development and decline\n",
    "    - explain lifespan differences in strategy selection learning from childhood to adulthood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future directions for the learning approach to decision making\n",
    "* Brain mechanisms of learning and decision making\n",
    "* Strategy selection and discovery\n",
    "* Social learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning approach must follow on the heuristics and biases’ and fast and frugal heuristics’ attempts to understand the circumstances under which different decision processes can lead to failure or success in adaptivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision makers are able to learn both about options and strategies to adapt their decisions to specific problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, much work lies ahead in understanding the role of learning processes in decision making. In the following, we anticipate a number of challenges and opportunities ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain mechanisms of learning and decision making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The theories described above represent an attempt to understand decision-making processes by integrating behavioral and computational theories of cognition.\n",
    "* A major goal of current decision theories is to bridge these theories with our knowledge of brain function to achieve a deeper understanding of the neural representation of cognitive mechanisms\n",
    "* A basic distinction can be made between associative and cognitive learning processes.\n",
    "* Considerable progress has been achieved of late in understanding reward processes and learning of options’ value in the brain.\n",
    "    - For example, Frank and Claus have proposed a connectionist model of how the mesencephalic dopamine system assesses and signals errors in reward prediction, which can be used to reinforce motor actions or decisions.\n",
    "* In contrast, the relation between strategy selection and the brain has not yet received the same level of attention and is thus not as well understood.\n",
    "    - Recent work on the neural substrates underlying the use of simple deci- sion strategies suggests that strategy selection processes may be associated with frontomedian activations, which represent assessments of the appropriateness of applying a strategy in a specific context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy selection and discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We dedicated a substantial portion of this chapter to presenting a compu- tational model of strategy selection learning, the SSL theory\n",
    "* SSL has some similarities with other extant models of strategy selection, such as \n",
    "    - reinforcement learning among cognitive strategies (RELACS)\n",
    "    - adaptive strategy choice model (ASCM)\n",
    "* Future work in the decision-making domain will need to evaluate the <font color=\"red\">power of considering information</font> other than past performance in strategy selection. \n",
    "* One aspect that learning models in decision making has yet to tackle is <font color=\"red\">strategy discovery</font>.\n",
    "    - Decision-making researchers may draw inspiration from models of skill acquisition such as the strategy choice and discovery simulation (SCADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We focused our analysis on individual learning; yet this is only one of many ways people learn to solve problems successfully. People often learn from observing others or from explicit advice they receive. <font color=\"red\">Social learning and culture undoubtedly play a crucial role in explaining human behavior.</font>\n",
    "* Nevertheless, other aspects of social learning may require more specific models and theories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In sum, we propose that learning is a “missing link” in decision-making research, because it provides an explanation of how people are able to adapt their decision making to specific situations. We thus hope to have contributed to showing how learning can help provide an account of how people acquire decision skills and why they succeed or fail in their decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료\n",
    "* [1] Judgment and Decision Making as a Skill: Learning, Development and Evolution - http://www.amazon.com/Judgment-Decision-Making-Skill-Development/dp/1107676525\n",
    "* [2] Simple Heuristics : That Make Us Smart - http://www.slideshare.net/guest27d3a1/gigerenzer\n",
    "* [3] The Oxford Handbook of Computational and Mathematical Psychology : chapter 10. Models of Decision Making under Risk and Uncertainty - http://www.amazon.com/Handbook-Computational-Mathematical-Psychology-Library/dp/0199957991\n",
    "* [4] (수리심리) 10. Models of Decision Making under Risk and Uncertainty / 모종훈 - https://drive.google.com/file/d/0Bw594TdiBdAUUTdjU2tyenN3Yjg/view\n",
    "* [5] Quantum Models of Cognition and Decision - http://www.slideshare.net/catarinapintomoreira/quantum-models-of-cognition-and-decision\n",
    "* [6] Neuroeconomics, Second Edition: Decision Making and the Brain - http://www.amazon.com/Neuroeconomics-Second-Decision-Making-Brain/dp/0124160085"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
